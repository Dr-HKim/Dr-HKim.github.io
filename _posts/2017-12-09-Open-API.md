---
layout: post  
title: R 에서 Open API 사용하기 (Using Open API in R)  
date: 2017-12-09  
category: [Data Analysis]  
tag: [R]  
author: hkim  
hidden: false # don't count this post in blog pagination  
image: /assets/images/icon/iconmonstr-monitoring-6-240.png
headerImage: true

---

***preface*** 이번 포스트에서는 Open API 서비스를 이용하여 R 로 직접 자료를 읽어오는 방법에 대하여 알아봅니다.


## 공공데이터 포털 - 아파트매매 실거래 상세 자료

다음 자료를 참고하였습니다:  
- [R 에서 open API 사용하기 _ 국토교통부 실거래가 정보를 가지고](http://blog.naver.com/PostView.nhn?blogId=juhy9212&logNo=221007989739&categoryNo=0&parentCategoryNo=0&viewDate=&currentPage=1&postListTopCurrentPage=1&from=postView)
- [부동산 매매가격 추이 분석](http://www.rpubs.com/lth1011/246453)

1. [공공데이터포털](https://www.data.go.kr/)에 접속하여 회원가입을 합니다.  
2. [국토교통부 실거래가정보 Open API](https://www.data.go.kr/dataset/3050988/openapi.do)에 들어갑니다.  
3. 아파트매매 실거래 상세 자료를 **활용 신청** 합니다.  
4. 바로 뜨는 안내 링크 혹은 마이페이지 > OPEN API > 개발계정 상세보기 에서 일반 인증키를 발급받습니다.  
5. 계발계정 상세보기 하단에 있는 개발가이드를 클릭하면 상세한 기술 문서를 얻을 수 있습니다.  
   - 요청주소: http://openapi.molit.go.kr/OpenAPI_ToolInstallPackage/service/rest/RTMSOBJSvc/getRTMSDataSvcAptTradeDev
   - 요청변수 항목을 보면 서비스키(ServiceKey), 지역코드(LAWD_CD), 계약월(DEAL_YMD) 이 필수임을 알 수 있습니다.


```r
library(XML)
library(data.table)
library(stringr)
library(ggplot2)

# Service Key
service_key <- "YOUR_SERVICE_KEY"

# 지역코드
locCode <-c("11110","11140","11170","11200","11215")

locCode_nm <-c("종로구","중구","용산구","성동구","광진구")

# 날짜
datelist <-c("201601","201602","201603","201604","201605","201606","201607","201608","201609","201610","201611","201612")

# 하나의 지역코드 x 날짜 당 출력 관측치 수 (따로 설정하지 않으면 default = 10 입니다)
Num_of_Rows <- 100

# 지역코드 x 날짜 별로 자료를 요청하는 url 생성
urllist <- list()
cnt <-0

for(i in 1:length(locCode)){
  for(j in 1:length(datelist)){
    cnt=cnt+1
    urllist[cnt] <-paste0("http://openapi.molit.go.kr/OpenAPI_ToolInstallPackage/service/rest/RTMSOBJSvc/getRTMSDataSvcAptTradeDev?LAWD_CD=",locCode[i],
                          "&DEAL_YMD=",datelist[j],
                          "&numOfRows=",Num_of_Rows,
                          "&serviceKey=",service_key)
  }
}

# 5 개 지역 x 12 개월 = 총 60 개의 url 요청
# (Open API 서비스에 따라 접속 횟수를 제한하기도 하므로 따로 저장)
# (아파트매매 실거래 상세 자료의 경우 하루 1000건)

raw.data <- list()
rootNode <- list()

for(i in 1:length(urllist)){
  raw.data[[i]] <- xmlTreeParse(urllist[i], useInternalNodes = TRUE,encoding = "utf-8") # 생성한 URL 대로 XML 을 요청한다
  rootNode[[i]] <- xmlRoot(raw.data[[i]])
}


# 저장한 XML을 분석가능한 형태로 수정

total<-list()

for(i in 1:length(urllist)){

  item <- list()
  item_temp_dt<-data.table()

  items <- rootNode[[i]][[2]][['items']] # items 항목만 골라낸다

  size <- xmlSize(items) # 몇개의 item 이 있는지 확인한다

  for(j in 1:size){
    item_temp <- xmlSApply(items[[j]],xmlValue)
    item_temp_dt <- data.table( GU      = locCode_nm[i%/%12+1],
                                GU_CODE = locCode[i%/%12+1],
                                DATE = datelist[(i-1)%%12+1],
                                VAR1=item_temp[1],
                                VAR2=item_temp[2],
                                VAR3=item_temp[3],
                                VAR4=item_temp[4],
                                VAR5=item_temp[5],
                                VAR6=item_temp[6],
                                VAR7=item_temp[7],
                                VAR8=item_temp[8],
                                VAR9=item_temp[9],
                                VAR10=item_temp[10],
                                VAR11=item_temp[11],
                                VAR12=item_temp[12],
                                VAR13=item_temp[13],
                                VAR14=item_temp[14],
                                VAR15=item_temp[15],
                                VAR16=item_temp[16],
                                VAR17=item_temp[17],
                                VAR18=item_temp[18],
                                VAR19=item_temp[19],
                                VAR20=item_temp[20],
                                VAR21=item_temp[21],
                                VAR22=item_temp[22],
                                VAR23=item_temp[23],
                                VAR24=item_temp[24])

    item[[j]]<-item_temp_dt
  }
  total[[i]] <- rbindlist(item)
}

RESULTS_APT_SALES <- rbindlist(total)

names(RESULTS_APT_SALES) <- c("시군구코드","시군구","날짜","거래금액","건축년도","년","도로명","도로명건물본번호코드","도로명건물부번호코드",
                              "도로명시군구코드","도로명일련번호코드","도로명지상지하코드","도로명코드","법정동",
                              "법정동본번코드","법정동부번코드","법정동시군구코드","법정도읍면동코드","법정동지번코드",
                              "아파트","월","일","일련번호","전용면적","지번","지역코드","층")
```

데이터를 받고나면, 중간중간 이가 빠진 데이터들 때문에 한번 더 cleansing 작업을 해줘야 합니다.

마지막 변수에 NA 가 들어간 자료들을 뽑아내서, 문제를 확인하고 수정하는 과정을 거칩시다.
